{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d51900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper import make_generator_model\n",
    "from Helper import train\n",
    "import tensorflow as tf\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "V2_LABELS_PATH = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v2.npy'\n",
    "VGGFACE_DIR = 'models/vggface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1091fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Generator and VGGFACE\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.random.set_seed(1)\n",
    "generator = make_generator_model()\n",
    "model = VGGFace(model='senet50')\n",
    "\n",
    "# Trainer settings\n",
    "EPOCHS = 3001\n",
    "BATCH = 5\n",
    "\n",
    "# Training Target\n",
    "fpath = get_file('rcmalli_vggface_labels_v2.npy', V2_LABELS_PATH, cache_subdir=VGGFACE_DIR)\n",
    "LABELS = np.load(fpath)\n",
    "## Format of ' FIRSTNAME_LASTNAME'\n",
    "Target_ID = np.where(LABELS == ' Whoopi_Goldberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af6ec4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 8365 - Whoopi_Goldberg\n",
      "Loss at Epoch 0 is 7.853772\n",
      "Loss at Epoch 50 is 5.6747017\n",
      "Loss at Epoch 100 is 0.397477\n",
      "Loss at Epoch 150 is 0.0704249\n",
      "Loss at Epoch 200 is 0.015182756\n",
      "Loss at Epoch 250 is 0.006005337\n",
      "Loss at Epoch 300 is 0.0025273636\n",
      "Loss at Epoch 350 is 0.0013396497\n",
      "Loss at Epoch 400 is 0.0010056217\n",
      "Loss at Epoch 450 is 0.0007960449\n",
      "Loss at Epoch 500 is 0.00054984057\n",
      "Loss at Epoch 550 is 0.00041526332\n",
      "Loss at Epoch 600 is 0.00033818505\n",
      "Loss at Epoch 650 is 0.00033785994\n",
      "Loss at Epoch 700 is 0.00019681019\n",
      "Loss at Epoch 750 is 0.00025019964\n",
      "Loss at Epoch 800 is 0.00013810181\n",
      "Loss at Epoch 850 is 0.0001741688\n",
      "Loss at Epoch 900 is 0.00023313313\n",
      "Loss at Epoch 950 is 0.00013830583\n",
      "Loss at Epoch 1000 is 0.00014243007\n",
      "Loss at Epoch 1050 is 0.00011177687\n",
      "Loss at Epoch 1100 is 0.00011722585\n",
      "Loss at Epoch 1150 is 0.00011701173\n",
      "Loss at Epoch 1200 is 8.120877e-05\n",
      "Loss at Epoch 1250 is 0.00010803365\n",
      "Loss at Epoch 1300 is 0.0001084276\n",
      "Loss at Epoch 1350 is 7.367412e-05\n",
      "Loss at Epoch 1400 is 0.00010308734\n",
      "Loss at Epoch 1450 is 7.334032e-05\n",
      "Loss at Epoch 1500 is 6.976408e-05\n",
      "Loss at Epoch 1550 is 7.989737e-05\n",
      "Loss at Epoch 1600 is 9.004395e-05\n",
      "Loss at Epoch 1650 is 5.943954e-05\n",
      "Loss at Epoch 1700 is 6.838091e-05\n",
      "Loss at Epoch 1750 is 6.47328e-05\n",
      "Loss at Epoch 1800 is 6.5114386e-05\n",
      "Loss at Epoch 1850 is 6.435128e-05\n",
      "Loss at Epoch 1900 is 4.797101e-05\n",
      "Loss at Epoch 1950 is 6.6282984e-05\n",
      "Loss at Epoch 2000 is 5.2882697e-05\n",
      "Loss at Epoch 2050 is 5.290676e-05\n",
      "Loss at Epoch 2100 is 4.3917677e-05\n",
      "Loss at Epoch 2150 is 5.355032e-05\n",
      "Loss at Epoch 2200 is 5.0283834e-05\n",
      "Loss at Epoch 2250 is 4.9020153e-05\n",
      "Loss at Epoch 2300 is 3.8052367e-05\n",
      "Loss at Epoch 2350 is 3.7074817e-05\n",
      "Loss at Epoch 2400 is 3.8290833e-05\n",
      "Loss at Epoch 2450 is 4.8495705e-05\n",
      "Loss at Epoch 2500 is 3.9530638e-05\n",
      "Loss at Epoch 2550 is 4.2964028e-05\n",
      "Loss at Epoch 2600 is 3.573964e-05\n",
      "Loss at Epoch 2650 is 3.0041192e-05\n",
      "Loss at Epoch 2700 is 3.2377775e-05\n",
      "Loss at Epoch 2750 is 2.9969688e-05\n",
      "Loss at Epoch 2800 is 3.0875693e-05\n",
      "Loss at Epoch 2850 is 3.5882797e-05\n",
      "Loss at Epoch 2900 is 3.16149e-05\n",
      "Loss at Epoch 2950 is 3.521507e-05\n",
      "Loss at Epoch 3000 is 2.2888453e-05\n",
      "Model saved after Epoch 3001\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: Saved_Models/ Whoopi_Goldberg_Model/generator-8365\\assets\n",
      "Loss Statistics Saved to CSV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c39d5743a0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "lr_sch = tf.keras.optimizers.schedules.ExponentialDecay(.1, 10000, .8, staircase = True)\n",
    "loss = [[],[]]\n",
    "\n",
    "print(\"Training \" + str(Target_ID[0][0]) + \" -\" + LABELS[Target_ID[0][0]]) \n",
    "\n",
    "tf.random.set_seed(1)\n",
    "for i in range(EPOCHS):\n",
    "    gen_opt = tf.keras.optimizers.Adam(lr_sch(i))\n",
    "    train(generator, model, gen_opt, BATCH, i, loss, Target_ID)\n",
    "\n",
    "print(\"Model saved after Epoch \" + str(EPOCHS))\n",
    "generator.save(\"Saved_Models/\" + LABELS[Target_ID[0][0]] + \"_Model/generator-\" + str(Target_ID[0][0]))\n",
    "\n",
    "print(\"Loss Statistics Saved to CSV\")\n",
    "np.savetxt(\"Loss_Stat/\" + str(Target_ID[0][0]) + \".csv\", loss, delimiter= ',')\n",
    "plt.plot(loss[0], loss[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
